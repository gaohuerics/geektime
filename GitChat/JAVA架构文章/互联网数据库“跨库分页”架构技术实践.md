## 内容提要

问：目前准备做数据库水平切分，需要注意什么关键问题？目前了解需要避免跨库事务，请老师指点。**

答：

1. 需要注意分库patitionkey的选取，要保证两个均衡：数据量的均衡，请求量的均衡。
2. 需要注意分库后，之前用SQL满足的需求是否还能满足，需要怎么改进满足，例如max、min、avg、sum都需要在服务层再做一次聚合。
3. 夸库事务，分布式事务，在吞吐量是主要矛盾的互联网场景，目前没有能够很好解决的方案，尽量避免。

------

**问：采用hash取模方式的表扩容策略及采用一致性hash分表的表扩容策略如何实现？**

答：数据库水平切分的方式，常用的有两种：

1. hash取模：`user_id%2=0`为0库，`user_id%2=1`为1库。
2. 数据分段：`user_id`属于[0, 1亿]为0库，属于[1亿, 2亿]为2库。

**方案一**

- 优点：简单、数据均衡、负载均衡。
- 缺点：扩容麻烦，要迁移数据，%2变%3不好弄。

**方案二**

- 优点：简单、数据均衡、扩容简单。
- 缺点：负载不均衡，大号段的库往往压力更大。

互联网95%使用方案一。

------

**问：1）上述的的几种分库方案我都用过了，取模的方案考虑到大表的增长速度总是难以预料，而且一旦确定了模数，要改还要考虑一堆兼容性问题，所以线上方案改造为除数的方法，缺点是时不时要去加下表。还有个问题，全局递增唯一键有没有什么高效的方案？2）目前有两种方案，放在缓存里自增，以及数据库自增，然而感觉这些逻辑拆的比较散，如利用缓存，还要考虑缓存丢失怎么办？3）mysql等数据库没有有一个分装好的这些分表解决方案呢？另外，你们一般业务用事务的情况多吗？**

答：1）成倍扩容可以实现平滑，之前有撰文专门写过，非常帅气的数据库秒级扩容方案；参考[《数据库秒级平滑扩容架构方案》](https://mp.weixin.qq.com/s/BLOneOs-cPxP_9b5eH8oQA)。

非成倍扩容需要进行数据迁移，如何实现不停服务，平滑的数据迁移，一言难尽，未来撰文详述。

2）对于唯一主键，一般有三类需求：

1. 全局唯一（强需求，必须满足）。
2. 全局趋势递增（有最好）。
3. 全局递增（比较难）。

解决方案有这么几种：

1. 数据库自增id，能够满足1，2，3，但性能差。
2. 数据库自增id+上游加一个服务，批量生成，能够满足1，2，3，性能较好，但可能出现id空洞（服务挂掉后，未分配出去的id不会再被分配了）。
3. uuid/guid，能够满足1，性能无限，但生成id很长64bit放不下，如果折半成64bit可能会出现id重复。
4. timeMS取毫秒数，能够满足2，但并发量大会重复。
5. 类snowflake算法，能够满足1、2，可以认为性能无限，是目前互联网圈用的最广的方法。

在[《细聊分布式ID生成方法》](https://mp.weixin.qq.com/s/0H-GEXlFnM1z-THI8ZGV2Q)中可见更详细的做法。

3）阿里，腾讯，百度，360都有一些实践，mycat也有人用，具体可以调研一下。

实现方式一般有两种，基于客户端的（阿里cobar），基于服务端的（百度dbproxy）至于事务，前台用户侧大数据，高并发业务，几乎不用事务。 钱相关的，单库会用事务，跨库事务也很难保证一致性。

多库事务可以参考这篇文章进行优化：[《多库多事务降低数据不一致概率》](https://mp.weixin.qq.com/s/FvB-hOBT13SMfZko5iagAg)。

------

**问：offset(pageNo-1)\*pageSize，limit pageSize。二次查询在分布不均的情况下，三页最小值远小于pageNo，比如333+0+0，极端情况下需要查询5次，如果pageNo=10000遇到这种情况怎么解决？**

答：如文章中第三种方案所述，“数据均衡原理”，一般数据分布是均匀的；极限情况下如果不均衡，第二次查询会返回大量的数据，性能会急剧下降。

------

**问：可以通过搜索引擎解决分页的问题吗？**

答：“准确率”和“召回率”作为评估指标，潜台词是，数据是不准确的。所以一般不用搜索引擎实现分页。如果业务能接受不准确，可以使用文章中的方案三。

------

**问：第四种不是还是需要进行内存排序么？如果单页请求书很大依然还是有问题的。**

答：不需要进行内存排序，排序的复杂度是`n*log(n)`。第四种方案，每一页返回的数据都是有序的，三个指针指向表头，比较表头，扫一遍可以得到全部顺序，复杂度为n，况且不需要全部扫一遍。

------

**问：在做服务化后，业务会拆分不同的库和不同表中。业务需求有时候需要连表模糊查询，查询结果还要分页。这个时候我们目前是做冗余字段，我想问一下有没有更好的解决方案？**

答：服务化之后，业务只提需求，是否连表，是服务层需要决定的。服务内部的库，即使连表，对调用方也透明。服务外部的库，无法连表，可以通过冗余数据解决。

架构设计，本身是方案折衷，要想高可用，必须冗余，一旦冗余，必定会有一致性问题，没有十全十美的方案，看业务主要矛盾了。

------

**问：这些分页方案的性能有多大差距？**

答：方案一，随着页码的增加，网络传输成n系数增加，排序性能成n*n指数增加。

方案二，性能是固定值，O(n)。

方案三，性能最好。

方案四，性能是固定值，O(n)，不过要查询2次。

------

**问：如果分库分表的情况下碰到要对一个表或多个表关联并且按多个字段为条件进行检索的情况下怎么办呢？**

答：所有人都在问分库后，join怎么办，我只能这么解释。

1. 前端用户侧业务，流量大，并发大，join真的很少，58同城用户库几亿数据，帖子库300亿数据，没有join。
2. 如果真要join，分库后冗余数据、索引表、分页，for循环低效查询 -> 总能解决的，只是看性能是不是主要矛盾、一致性是不是主要矛盾了。

拆成小sql是互联网的玩法，互联网很少用join、子查询、视图、外键、用户自定义函数、存储过程的。当然，我指面向用户侧的业务。

------

**问：据说mycat可以解决分库的join问题，就是不知道性能如何？**

答：我猜测，1. 解决了部分；2. 性能不会太好。

参见[《58到家数据库30条军规解读》](https://mp.weixin.qq.com/s/Yjh_fPgrjuhhOZyVtRQ-SA)和[《再议数据库军规》](https://mp.weixin.qq.com/s/8LHNXdpRcn_ehIdb8Q4EvA)，我们的mysql这么玩。

------

**问：沈老师推荐什么中间件呢？解决什么问题？ “服务化+分库”能解决么？**

答：中间件，58同城是自研的。

服务化的第一条：不服务化（弄清楚为什么要服务化，解决什么问题）。

分库的第一条：不分库（弄清楚为什么要分库，解决什么问题）。

58到家目前没有用中间件，分库的业务很少，分库后都是服务层做聚合。

------

**问：单表多大数据量时才考虑分库分表？**

答：“单表多大数据量时才考虑分库分表”，我们的经验，mysql，1000w，要考虑分了。如果查询比较简单，5000w。

------

**问：相同的查询条件，生成不同的报表（如：按媒体类型、媒体、正负面等），数据量大的情况有哪些解决方案？**

答：报表这类非实时需求，让擅长大数据计算的平台搞比较合适。 每个公司应该都有BI，haddop，数据仓库等，解决报表类需求比较好。单表多大数据考虑拆分，还是看业务场景，用户表，uid查询，1亿没问题。

------

**问：军规里面写了单库500表，请问是怎么考虑的？目前我们有分表上千了。**

答：1000表，单库，耦合估计很严重（特别是join多的话），未来数据量大了，不好拆。

------

**问：我们业务使用了1000个分片表，这样可以吗？**

答：个人建议，一律使用分库，而不是分表。

分表：

1. 表名不同吧？DAO层搞一个实例，还是多个实例，还是怎么trick一下？
2. 物理上，还是在一个库文件里，还是有潜在瓶颈。
3. 未来扩展到多机，比较麻烦。

所以，建议一律分库。

副作用是，数据库连接会比较多，但一般不是瓶颈。我发现数据库的文章，大家比较喜欢读。我花了好几天写的“搜索引擎”的文章，阅读量比较低 =_=

------

**问：跨库后增加数据库主机，每个表实现再散列后，在保持服务的情况下，如何更新表的数据呢？**

答：非常好的问题，如何实现不停服务，平滑的数据迁移，至少有两种方案，



## 文章实录



### 一、需求缘起

#### 分页需求

互联网很多业务都有分页拉取数据的需求，例如：

1. 微信消息过多时，拉取第N页消息。
2. 京东下单过多时，拉取第N页订单。
3. 浏览58同城，查看第N页帖子。

这些业务场景对应的消息表，订单表，帖子表分页拉取需求有这样一些特点：

1. **有一个业务主键id**，例如`msg_id`，`order_id`，`tiezi_id`
2. **分页排序是按照非业务主键id来排序的**，业务中经常按照时间time来排序order by

在数据量不大时，可以通过在排序字段time上建立索引，利用SQL提供的offset/limit功能就能满足分页查询需求：

```
select * from t_msg order by time offset 200 limit 100 
select * from t_order order by time offset 200 limit 100 
select * from t_tiezi order by time offset 200 limit 100 

```

此处假设一页数据为100条，均拉取第3页数据。

#### 分库需求

高并发大流量的互联网架构，一般通过服务层来访问数据库，随着数据量的增大，数据库需要进行水平切分，分库后将数据分布到不同的数据库实例（甚至物理机器）上，以达到降低数据量，增加实例数的扩容目的。

一旦涉及分库，逃不开**“分库依据”patition key**的概念，使用哪一个字段来水平切分数据库呢：**大部分的业务场景，会使用业务主键id**。

确定了分库依据patition key后，接下来要确定的是**分库算法**：大部分的业务场景，会使用**业务主键id取模的算法来分库**，这样即能够保证每个库的数据分布是均匀的，又能够保证每个库的请求分布是均匀的，实在是简单实现负载均衡的好方法，此法在互联网架构中应用颇多。

举一个更具体的例子：

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/0a1c2b30-f69f-11e6-bfb2-ed01f1eed323)

用户库user，水平切分后变为两个库，**分库依据patition key是uid**，**分库算法是uid取模**：uid%2余0的数据会落到db0，uid%2余1的数据会落到db1。

#### 问题的提出

仍然是上述用户库的例子，如果业务要查询“最近注册的第3页用户”，该如何实现呢？单库上，可以`select * from t_user order by time offset 200 limit 100`，变成两个库后，分库依据是uid，排序依据是time，数据库层失去了time排序的全局视野，数据分布在两个库上，此时该怎么办呢？

如何满足**“跨越多个水平切分数据库，且分库依据与排序依据为不同属性，并需要进行分页”**的查询需求，实现`select*from T order by time offset X limit Y`的跨库分页SQL，是本文将要讨论的技术问题。

### 二、全局视野法

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/16eccef0-f69f-11e6-bfb2-ed01f1eed323)

如上图所述，服务层通过uid取模将数据分布到两个库上去之后，每个数据库都失去了全局视野，数据按照time局部排序之后，不管哪个分库的第3页数据，都不一定是全局排序的第3页数据。

那到底哪些数据才是全局排序的第3页数据呢，暂且分三种情况讨论。

**（1）极端情况，两个库的数据完全一样**

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/21061ae0-f69f-11e6-bfb2-ed01f1eed323)

如果两个库的数据完全相同，只需要每个库offset一半，再取半页，就是最终想要的数据（如上图中粉色部分数据）。

**（2）极端情况，结果数据来自一个库**

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/28648c90-f69f-11e6-bfb2-ed01f1eed323)

也可能两个库的数据分布及其不均衡，例如db0的所有数据的time都大于db1的所有数据的time，则可能出现：一个库的第3页数据，就是全局排序后的第3页数据（如上图中粉色部分数据）。

**（3）一般情况，每个库数据各包含一部分**

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/2f0616e0-f69f-11e6-bfb2-ed01f1eed323)

正常情况下，全局排序的第3页数据，每个库都会包含一部分（如上图中粉色部分数据）。

由于不清楚到底是哪种情况，所以必须每个库都返回3页数据，所得到的6页数据在服务层进行内存排序，得到数据全局视野，再取第3页数据，便能够得到想要的全局分页数据。

再总结一下这个方案的步骤：

1. 将`order by time offset X limit Y`，改写成`order by time offset 0 limit X+Y`。
2. 服务层将改写后的SQL语句发往各个分库：即例子中的各取3页数据。
3. 假设共分为N个库，服务层将得到N*(X+Y)条数据：即例子中的6页数据。
4. 服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录，就是全局视野所需的一页数据。

**方案优点**：通过服务层修改SQL语句，扩大数据召回量，能够得到全局视野，业务无损，精准返回所需数据。

**方案缺点（显而易见）**：

1. 每个分库需要返回更多的数据，增大了网络传输量（耗网络）；
2. 除了数据库按照time进行排序，服务层还需要进行二次排序，增大了服务层的计算量（耗CPU）；
3. 最致命的，这个算法随着页码的增大，性能会急剧下降，这是因为SQL改写后每个分库要返回X+Y行数据：返回第3页，offset中的X=200；假如要返回第100页，offset中的X=9900，即每个分库要返回100页数据，数据量和排序量都将大增，性能平方级下降。

### 三、业务折衷法

“全局视野法”虽然性能较差， 但其业务无损，数据精准，不失为一种方案，有没有性能更优的方案呢？

**“任何脱离业务的架构设计都是耍流氓”**，技术方案需要折衷，在技术难度较大的情况下，**业务需求的折衷能够极大的简化技术方案**。

#### 业务折衷一：禁止跳页查询

在数据量很大，翻页数很多的时候，很多产品并**不提供“直接跳到指定页面”的功能，而只提供“下一页”的功能**，这一个小小的业务折衷，就能极大的降低技术方案的复杂度。

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/45d2e1a0-f69f-11e6-bfb2-ed01f1eed323)

如上图，不能够跳页，那么第一次只能够查询第一页：

1. 将查询`order by time offset 0 limit 100`，改写成`order by time where time>0 limit 100`。
2. 上述改写和`offset 0 limit 100`的效果相同，都是每个分库返回了一页数据（上图中粉色部分）。
   ![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/519d11e0-f69f-11e6-bfb2-ed01f1eed323)
3. 服务层得到2页数据，内存排序，取出前100条数据，作为最终的第一页数据，这个全局的第一页数据，一般来说每个分库都包含一部分数据（如上图粉色部分）。

咦，这个方案也需要服务器内存排序，岂不是和“全局视野法”一样么？第一页数据的拉取确实一样，但每一次“下一页”拉取的方案就不一样了。

点击“下一页”时，需要拉取第二页数据，在第一页数据的基础之上，能够找到第一页数据time的最大值：

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/720e46b0-f69f-11e6-bfb2-ed01f1eed323)

这个上一页记录的`time_max`，**会作为第二页数据拉取的查询条件**：

1. 将查询order by time offset 100 limit 100，改写成`order by time where time>$time_max limit 100`。
   ![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/8992efc0-f69f-11e6-bfb2-ed01f1eed323)
2. 这下不是返回2页数据了（“全局视野法，会改写成`offset 0 limit 200`”），每个分库还是返回一页数据（如上图中粉色部分）。
   ![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/93d28860-f69f-11e6-bfb2-ed01f1eed323)
3. 服务层得到2页数据，内存排序，取出前100条数据，作为最终的第2页数据，这个全局的第2页数据，一般来说也是每个分库都包含一部分数据（如上图粉色部分）。

如此往复，查询全局视野第100页数据时，不是将查询条件改写为`offset 0 limit 9900+100`（返回100页数据），而是改写为`time>$time_max99 limit 100`（仍返回一页数据），以保证**数据的传输量和排序的数据量不会随着不断翻页而导致性能下降**。

#### 业务折衷二：允许数据精度损失

“全局视野法”能够返回业务无损的精确数据，在查询页数较大，例如第100页时，会有性能问题，此时业务上是否能够接受，返回的100页不是精准的数据，而允许有一些数据偏差呢？

**数据库分库-数据均衡原理**

使用patition key进行分库，在数据量较大，数据分布足够随机的情况下，各分库所有非patition key属性，在各个分库上的数据分布，统计概率情况应该是一致的。

例如，在uid随机的情况下，使用uid取模分两库，db0和db1：

1. 性别属性，如果db0库上的男性用户占比70%，则db1上男性用户占比也应为70%；

2. 年龄属性，如果db0库上18-28岁少女用户比例占比15%，则db1上少女用户比例也应为15%；

3. 时间属性，如果db0库上每天10:00之前登录的用户占比为20%，则db1上应该是相同的统计规律；
   …

   ![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/ba8ffb90-f69f-11e6-bfb2-ed01f1eed323)

利用这一原理，要查询全局100页数据，`offset 9900 limit 100`改写为`offset 4950 limit 50`，每个分库偏移4950（一半），获取50条数据（半页），得到的数据集的并集，基本能够认为，是全局数据的`offset 9900 limit 100`的数据，当然，这一页数据的精度，并不是精准的。

根据实际业务经验，用户都要查询第100页网页、帖子、邮件的数据了，这一页数据的精准性损失，业务上往往是可以接受的，但此时技术方案的复杂度便大大降低列，既不需要返回更多的数据，也不需要进行服务内存排序了。

### 四、终极武器：二次查询法

有没有一种技术方案，即能够满足业务的精确需要，无需业务折衷，又高性能的方法呢？这就是接下来要介绍的终极武器：“二次查询法”。

为了方便举例，假设一页只有5条数据，查询第200页的SQL语句为`select*from T order by time offset 1000 limit 5`。

#### 步骤一：查询改写

将`select*from T order by time offset 1000 limit 5`改写为`select*from T order by time offset 500 limit 5`并投递给所有的分库，注意，这个offset的500，来自于全局offset的总偏移量1000，除以水平切分数据库个数2。

如果是3个分库，则可以改写为`select*from T order by time offset 333 limit 5`，假设这三个分库返回的数据`(time, uid)`如下：

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/ca8beea0-f69f-11e6-bfb2-ed01f1eed323)

可以看到，每个分库都是返回的按照time排序的一页数据。

#### 步骤二：找到所返回3页全部数据的最小值

- 第一个库，5条数据的time最小值是1487501123

- 第二个库，5条数据的time最小值是1487501133

- 第三个库，5条数据的time最小值是1487501143

  ![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/d64778e0-f69f-11e6-bfb2-ed01f1eed323)

故，三页数据中，time最小值来自第一个库，time_min=1487501123，这个过程只需要比较各个分库第一条数据，时间复杂度很低。

#### 步骤三：查询二次改写

第一次改写的SQL语句是`select*from T order by time offset 333 limit 5`。第二次要改写成一个between语句，between的起点是`time_min`，between的终点是原来每个分库各自返回数据的最大值：

第一个分库，第一次返回数据的最大值是1487501523；所以查询改写为`select*from T order by time where time between time_min and 1487501523`。

第二个分库，第一次返回数据的最大值是1487501323；所以查询改写为`select*from T order by time where time between time_min and 1487501323`。

第三个分库，第一次返回数据的最大值是1487501553；所以查询改写为`select*from T order by time where time between time_min and 1487501553`。

相对第一次查询，第二次查询条件放宽了，故第二次查询会返回比第一次查询结果集更多的数据，假设这三个分库返回的数据`(time, uid)`如下：

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/e17a2410-f69f-11e6-bfb2-ed01f1eed323)

可以看到：

- 由于`time_min`来自原来的分库一，所以分库一的返回结果集和第一次查询相同（所以其实这次查询是可以省略的）；
- 分库二的结果集，比第一次多返回了1条数据，头部的1条记录（time最小的记录）是新的（上图中粉色记录）；
- 分库三的结果集，比第一次多返回了2条数据，头部的2条记录（time最小的2条记录）是新的（上图中粉色记录）。

#### 步骤四：在每个结果集中虚拟一个`time_min`记录，找到`time_min`在全局的offset

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/ee8782b0-f69f-11e6-bfb2-ed01f1eed323)

- 在第一个库中，`time_min`在第一个库的offset是333；
- 在第二个库中，`(1487501133, uid_aa)`的offset是333（根据第一次查询条件得出的），故虚拟`time_min`在第二个库的offset是331；
- 在第三个库中，`(1487501143, uid_aaa)`的offset是333（根据第一次查询条件得出的），故虚拟`time_min`在第三个库的offset是330。

综上，`time_min`在全局的offset是333+331+330=994。

#### 步骤五：既然得到了`time_min`在全局的offset，就相当于有了全局视野，根据第二次的结果集，就能够得到全局`offset 1000 limit 5`的记录

![enter image description here](http://7xpvay.com1.z0.glb.clouddn.com/fae71520-f69f-11e6-bfb2-ed01f1eed323)

第二次查询在各个分库返回的结果集是有序的，又知道了`time_min`在全局的offset是994，一路排下来，容易知道全局`offset 1000 limit 5`的一页记录（上图中黄色记录）。

是不是非常巧妙？这种方法的**优点**是：可以精确的返回业务所需数据，每次返回的数据量都非常小，不会随着翻页增加数据的返回量。

**不足**是：需要进行两次数据库查询。

### 五、总结

今天分享了解决“夸N库分页”这一技术难题的四种方法，稍作总结：

#### 方法一：全局视野法

1. 将`order by time offset X limit Y`，改写成`order by time offset 0 limit X+Y`。
2. 服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录。

#### 方法二：业务折衷法-禁止跳页查询

1. 用正常的方法取得第一页数据，并得到第一页记录的`time_max`。
2. 每次翻页，将`order by time offset X limit Y`，改写成`order by time where time>$time_max limit Y`以保证每次只返回一页数据，性能为常量。

#### 方法三：业务折衷法-允许模糊数据

将`order by time offset X limit Y`，改写成`order by time offset X/N limit Y/N`。

#### 方法四：二次查询法

1. 将`order by time offset X limit Y`，改写成`order by time offset X/N limit Y`；
2. 找到最小值`time_min`；
3. between二次查询，`order by time between $$time_min and $time_i_max`；
4. 设置虚拟`time_min`，找到`time_min`在各个分库的offset，从而得到`time_min`在全局的offset；
5. 得到了`time_min`在全局的offset，自然得到了全局的`offset X limit Y`。
6. ​

## 